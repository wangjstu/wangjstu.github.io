{"meta":{"title":"typoway","subtitle":"‘wangjstu`s blog'","description":"Eat your own dog food","author":"wangjstu","url":"http://wangjstu.github.io","root":"/"},"pages":[{"title":"404 Not Found：该页无法显示","date":"2020-07-02T18:24:25.417Z","updated":"2020-07-02T18:24:25.417Z","comments":false,"path":"/404.html","permalink":"http://wangjstu.github.io/404.html","excerpt":"","text":""},{"title":"关于","date":"2020-07-02T18:24:25.418Z","updated":"2020-07-02T18:24:25.418Z","comments":false,"path":"about/index.html","permalink":"http://wangjstu.github.io/about/index.html","excerpt":"","text":"个人详细介绍"},{"title":"书单","date":"2020-07-02T18:24:25.419Z","updated":"2020-07-02T18:24:25.419Z","comments":false,"path":"books/index.html","permalink":"http://wangjstu.github.io/books/index.html","excerpt":"","text":""},{"title":"分类","date":"2020-07-02T18:24:25.419Z","updated":"2020-07-02T18:24:25.419Z","comments":false,"path":"categories/index.html","permalink":"http://wangjstu.github.io/categories/index.html","excerpt":"","text":""},{"title":"标签","date":"2020-07-02T18:24:25.420Z","updated":"2020-07-02T18:24:25.420Z","comments":false,"path":"tags/index.html","permalink":"http://wangjstu.github.io/tags/index.html","excerpt":"","text":""},{"title":"友情链接","date":"2020-07-02T18:24:25.419Z","updated":"2020-07-02T18:24:25.419Z","comments":true,"path":"links/index.html","permalink":"http://wangjstu.github.io/links/index.html","excerpt":"","text":""},{"title":"Repositories","date":"2020-07-02T18:24:25.420Z","updated":"2020-07-02T18:24:25.420Z","comments":false,"path":"repository/index.html","permalink":"http://wangjstu.github.io/repository/index.html","excerpt":"","text":""}],"posts":[{"title":"关于shell文件中换行符和回车的故事","slug":"the-story-of-carriage-return-and-line-feed-in-shell-file","date":"2023-07-23T07:27:29.000Z","updated":"2023-07-23T07:27:29.000Z","comments":true,"path":"2023/07/23/the-story-of-carriage-return-and-line-feed-in-shell-file/","link":"","permalink":"http://wangjstu.github.io/2023/07/23/the-story-of-carriage-return-and-line-feed-in-shell-file/","excerpt":"","text":"故事概览* 这个故事发生持续了1个小时，现象是一个shell脚本报了ambiguous redirect错，过程是自己花了一个小时查了一圈，经验教训是shell脚本换行一定要是LF(\\n)，文件格式一定要是unix的。 * 这个故事很简单，但是有些许知识或经验值得记录，以备参考。 故事问题* 一个简单的shell脚本运行报如下错误： 123456789101112131415[wangjstu@wangjstupc]$ sh /tmp/test.sh: ambiguous redirect /tmp/test.sh: line 2: 1: ambiguous redirect /tmp/test.sh: line 3: 1[wangjstu@wangjstupc]$ cat /tmp/test.sh#!/bin/shphp /tmp/cache1.php &gt;/dev/null 2&gt;&amp;1php /tmp/cache2.php &gt;/dev/null 2&gt;&amp;1 分析排查过程* 第一眼看到错误ambiguous redirect，结合“字面意思”+stackoverflow，怀疑的是重定向输入&gt;/dev/null这里有问题，结合前人经验+单独运行单个php命令成功，判定我这边不是这个原因。 &gt; 网上ambiguous redirect大部分原因是重定向输入的对象用变量的传递，变量没有正确赋值导致 * 排除了重定向输入问题，再仔细看了几篇stackoverflow，有个牛人说，这类报错还有一种原因是上下文有问题，朝着这个思路去排查，shell脚本里面添加set -ex，看下是否有详细报错，结果报错还是类似的，但确定一点，我的脚本肯定上下文肯定有问题。 * 直接用strace跟了一下，看到了一行read(3, &quot;#!/bin/sh\\r\\nphp5 /tmp/cache1.php&quot;..., 80) = 80，当看到\\r\\n，自己顿时就秒清醒，是文件格式问题。 解决方法* 本人实际问题原因：shell脚本格式是dos类型的，内容里面缓缓是windows下的换行\\r\\n，而标准要求是\\n，所以会有如上错误。以前开发中使用编辑器会注意，但是本次是直接在服务器上，一开始没有往这个方向想，所以绕了弯路，不过沿途“风景”略过，还是值得记录一下。 * 解决问题命令：sed -i &#39;s/\\r//&#39; /tmp/test.sh 拓展思考到的问题如何检查shell脚本语法* bash -n script_name.sh &#x2F;&#x2F;-n选项只做语法检查，而不执行脚本。然而换行的问题无法检查出来。 * shell脚本里面添加 set -x ，将shell实际运行命令输出，可以查看具体执行语句，也可以查出语法的一些问题。 CRLF(\\r\\n)、LF(\\n)区别* LF(\\n)，Carriage Return（回车符），ASCII代码是10，十六制为0x0A，适用于Unix系统(包括Linux, MacOS近些年的版本)。 * CR(\\r)，Line Feed（换行符，返回光标到左边），十进制ASCII代码是13，十六进制代码为0x0D，一般显示^M，这个^M要用ctrl + v ctrl + m打出按出，在MAC OS 9或之前版本中用。 * CRLF(\\r\\n)，Carriage Return Line Feed （回车换行符），适用于windows操作系统。 如何查看shell脚本中换行是CRLF(\\r\\n)还是LF(\\n)cat* cat -A filename.txt &#x2F;&#x2F;windows下创建的文件换行符为^M$，linux格式是换行符$ vim :set ff? ffs? &#x2F;&#x2F;查看文件格式 :verbose set ff? ffs? &#x2F;&#x2F;查看文件格式及最后一次设置源头 输出结果和对应操作系统的换行： ffs&#x3D;unix,dos Unix based systems ffs&#x3D;dos,unix Windows and DOS systems ffs&#x3D;mac,unix,dos Mac OS 9 systems :e ++ff=unix，使用unix格式读取重新读取文件，如果是CRLF(\\r\\n)，可以看到^M，对应的:e ++ff=dos 使用dos查看文件格式。 ob ob -t x1 filename.txt &#x2F;&#x2F;使用二进制查看文件格式，如果有0D 0A则是CRLF(\\r\\n)，有0A 则是LF(\\n) ###转换文件格式 如何转换文件内容中CRLF(\\r\\n)为LF(\\n)* dos2unix * vim方式一，不要求文件中换行统一一样，也就是CRLF(\\r\\n)、LF(\\n)都转为CRLF(\\r\\n) 123456789:update //保存修改:e ++ff=dos //使用dos格式打开文件，同时可以有CRLF(\\r\\n)、LF(\\n):setlocal ff=unix //将缓冲区的内容使用LF(\\n)作为行结尾写入文件，setlocal=setl，避免更改全局默认值。:w //将缓冲区写入文件 * vim方式二，要求文件中换行统一一样都是CRLF(\\r\\n)，如果有LF(\\n)就会报错 12345:args *.c *.h //限定后缀的文件修改:argdo set ff=unix|update //修改文件格式并修改为LF(\\n)换行。如果同时打开多个文件，可以使用命令`:bufdo! set ff=unix|w`一次全修改。 * sed：sed &#39;s/\\r//g&#39; filename.txt &gt; modified.txt 如何转换文件内容中LF(\\n)为CRLF(\\r\\n)* dos2unix * vim方式一，不要求文件中换行统一一样，也就是CRLF(\\r\\n)、LF(\\n)都转为CRLF(\\r\\n) 1234567:update //保存修改:e ++ff=dos //使用dos格式打开文件:w //将缓冲区写入文件 * vim方式二，要求文件中换行统一一样LF(\\n)，当存在CRLF(\\r\\n)，就会报错 12345:args *.c *.h //限定文件格式:argdo set ff=dos|update //转换文件换行为CRLF(\\r\\n).如果同时打开多个文件，可以使用命令`:bufdo! set ff=dos|w`一次全修改。 sed 12345sed &quot;:a;N;s/\\n//g;$!ba&quot; filename.txtsed &quot;:a;N;s/\\n//g;ta&quot; filename.txt 参考 Carriage_return Line_feed File format","categories":[{"name":"Shell","slug":"Shell","permalink":"http://wangjstu.github.io/categories/Shell/"}],"tags":[{"name":"回车","slug":"回车","permalink":"http://wangjstu.github.io/tags/%E5%9B%9E%E8%BD%A6/"},{"name":"换行符","slug":"换行符","permalink":"http://wangjstu.github.io/tags/%E6%8D%A2%E8%A1%8C%E7%AC%A6/"}]},{"title":"Email协议： POP3，SMTP，IMAP 初识","slug":"Email-Protocols-POP3-SMTP-and-IMAP","date":"2020-12-28T04:02:23.000Z","updated":"2020-12-28T04:02:23.000Z","comments":true,"path":"2020/12/28/Email-Protocols-POP3-SMTP-and-IMAP/","link":"","permalink":"http://wangjstu.github.io/2020/12/28/Email-Protocols-POP3-SMTP-and-IMAP/","excerpt":"","text":"概要主要通过以下三个方面进行介绍（what、which）： POP3是什么及使用端口 IMAP是什么及使用端口 SMTP是什么及使用端口 POP3协议内容及端口 POP3(Post Office Protocol version 3)是本地邮箱客户端从远程服务端收取邮件的标准协议。POP3协议允许你将邮件内容下载到本地电脑，离线阅读。需要注意的是，使用POP3协议，邮件收取下载到本地后，远程服务端的邮件会被移除。使用POP3的好处：邮件一经下载到本地，远程服务端会删除，减少了邮箱服务端存储邮件内容的空间；弊端：对多应用端配置同一个邮箱不友好，你在多台设备上查看邮件，可能会因为前面的某一设备下载了，后面的设备就看不到这个邮件了。 默认情况下，POP3可选用以下2个端口： 端口110：默认设置端口，不加密； 端口995：如果你期望加密安全，使用这个端口。 IMAP协议内容及端口 IMAP(Internet Message Access Protocol)是与POP3协议极为类似的收取邮件的协议，类似云存储，异地异端可同时获取。最大的区别是：IMAP协议允许同时多个客户端从邮箱远程服务端收取邮件，邮件最终存储在远程服务端，本地仅是缓存的邮件，适用于多端同一邮箱场景使用。 默认情况下，IMAP可选用以下2个端口： 端口143：默认设置端口，不加密； 端口993：如果你期望加密安全，使用这个端口。 SMTP协议内容及端口 SMTP(Simple Mail Transfer Protocol)是标准的互联网邮件发送协议。 默认情况下，SMTP可选用以下3个端口： 端口25：默认设置端口，不加密； 端口2525：备用设置端口，当托管服务器25被屏蔽时使用，不加密； 端口465：加密发送邮件协议端口。 个人画外音 写这篇文章原因是，身边有同事邮件莫名其名丢了，主要原因是使用了POP3协议收取邮件，次要原因是办公硬盘小，有时候清理～误操作。建议大家收取邮件都选用协议 IMAP，993端口。SMTP发送邮件选用465端口。 英文原文 Email Protocols - POP3, SMTP and IMAP Tutorial","categories":[{"name":"Protocols","slug":"Protocols","permalink":"http://wangjstu.github.io/categories/Protocols/"}],"tags":[{"name":"Protocols","slug":"Protocols","permalink":"http://wangjstu.github.io/tags/Protocols/"},{"name":"POP3","slug":"POP3","permalink":"http://wangjstu.github.io/tags/POP3/"},{"name":"SMTP","slug":"SMTP","permalink":"http://wangjstu.github.io/tags/SMTP/"},{"name":"IMAP","slug":"IMAP","permalink":"http://wangjstu.github.io/tags/IMAP/"}]},{"title":"Linux tar handbook","slug":"Linux-tar-handbook","date":"2020-08-02T15:02:58.000Z","updated":"2020-08-02T15:02:58.000Z","comments":true,"path":"2020/08/02/Linux-tar-handbook/","link":"","permalink":"http://wangjstu.github.io/2020/08/02/Linux-tar-handbook/","excerpt":"","text":"Tar语法详解 tar 命令帮助信息，包括语法基础：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294用法: tar [选项...] [FILE]... GNU ‘tar’将许多文件一起保存至一个单独的磁带或磁盘归档，并能从归档中单独还原所需文件。示例 tar -cf archive.tar foo bar # 从文件 foo 和 bar 创建归档文件archive.tar。 tar -tvf archive.tar # 详细列举归档文件 archive.tar中的所有文件。 tar -xf archive.tar # 展开归档文件 archive.tar中的所有文件。 主操作模式: -A, --catenate, --concatenate 追加 tar 文件至归档 -c, --create 创建一个新归档 -d, --diff, --compare 找出归档和文件系统的差异 --delete 从归档(非磁带！)中删除 -r, --append 追加文件至归档结尾 -t, --list 列出归档内容 --test-label 测试归档卷标并退出 -u, --update 仅追加比归档中副本更新的文件 -x, --extract, --get 从归档中解出文件 操作修饰符: --check-device 当创建增量归档时检查设备号(默认) -g, --listed-incremental=FILE 处理新式的 GNU 格式的增量备份 -G, --incremental 处理老式的 GNU 格式的增量备份 --ignore-failed-read 当遇上不可读文件时不要以非零值退出 --level=NUMBER 所创建的增量列表归档的输出级别 -n, --seek 归档可检索 --no-check-device 当创建增量归档时不要检查设备号 --no-seek 归档不可检索 --occurrence[=NUMBER] 仅处理归档中每个文件的第 NUMBER 个事件；仅当与以下子命令 --delete, --diff, --extract 或是 --list 中的一个联合使用时，此选项才有效。而且不管文件列表是以命令行形式给出或是通过-T 选项指定的；NUMBER 值默认为 1 --sparse-version=MAJOR[.MINOR] 设置所用的离散格式版本(隐含 --sparse) -S, --sparse 高效处理离散文件 重写控制: -k, --keep-old-files don&#x27;t replace existing files when extracting, treat them as errors --keep-directory-symlink preserve existing symlinks to directories when extracting --keep-newer-files 不要替换比归档中副本更新的已存在的文件 --no-overwrite-dir 保留已存在目录的元数据 --overwrite 解压时重写存在的文件 --overwrite-dir 解压时重写已存在目录的元数据(默认) --recursive-unlink 解压目录之前先清除目录层次 --remove-files 在添加文件至归档后删除它们 --skip-old-files don&#x27;t replace existing files when extracting, silently skip over them -U, --unlink-first 在解压要重写的文件之前先删除它们 -W, --verify 在写入以后尝试校验归档 选择输出流: --ignore-command-error 忽略子进程的退出代码 --no-ignore-command-error 将子进程的非零退出代码认为发生错误 -O, --to-stdout 解压文件至标准输出 --to-command=COMMAND 将解压的文件通过管道传送至另一个程序 操作文件属性: --atime-preserve[=METHOD] 在输出的文件上保留访问时间，要么通过在读取(默认 METHOD=‘replace’)后还原时间，要不就不要在第一次(METHOD=‘system’)设置时间 --delay-directory-restore 直到解压结束才设置修改时间和所解目录的权限 --group=名称 强制将 NAME 作为所添加的文件的组所有者 --mode=CHANGES 强制将所添加的文件(符号)更改为权限 CHANGES --mtime=DATE-OR-FILE 从 DATE-OR-FILE 中为添加的文件设置 mtime -m, --touch 不要解压文件的修改时间 --no-delay-directory-restore 取消 --delay-directory-restore 选项的效果 --no-same-owner 将文件解压为您所有(普通用户默认此项) --no-same-permissions 从归档中解压权限时使用用户的掩码位(默认为普通用户服务) --numeric-owner 总是以数字代表用户/组的名称 --owner=名称 强制将 NAME 作为所添加的文件的所有者 -p, --preserve-permissions, --same-permissions 解压文件权限信息(默认只为超级用户服务) --preserve 与 -p 和 -s 一样 --same-owner 尝试解压时保持所有者关系一致(超级用户默认此项) -s, --preserve-order, --same-order member arguments are listed in the same order as the files in the archive Handling of extended file attributes: --acls Enable the POSIX ACLs support --no-acls Disable the POSIX ACLs support --no-selinux Disable the SELinux context support --no-xattrs Disable extended attributes support --selinux Enable the SELinux context support --xattrs Enable extended attributes support --xattrs-exclude=MASK specify the exclude pattern for xattr keys --xattrs-include=MASK specify the include pattern for xattr keys 设备选择和切换: -f, --file=ARCHIVE 使用归档文件或 ARCHIVE 设备 --force-local 即使归档文件存在副本还是把它认为是本地归档 -F, --info-script=名称, --new-volume-script=名称 在每卷磁带最后运行脚本(隐含 -M) -L, --tape-length=NUMBER 写入 NUMBER × 1024 字节后更换磁带 -M, --multi-volume 创建/列出/解压多卷归档文件 --rmt-command=COMMAND 使用指定的 rmt COMMAND 代替 rmt --rsh-command=COMMAND 使用远程 COMMAND 代替 rsh --volno-file=FILE 使用/更新 FILE 中的卷数 设备分块: -b, --blocking-factor=BLOCKS 每个记录 BLOCKS x 512 字节 -B, --read-full-records 读取时重新分块(只对 4.2BSD 管道有效) -i, --ignore-zeros 忽略归档中的零字节块(即文件结尾) --record-size=NUMBER 每个记录的字节数 NUMBER，乘以 512 选择归档格式: -H, --format=FORMAT 创建指定格式的归档 FORMAT 是以下格式中的一种: gnu GNU tar 1.13.x 格式 oldgnu GNU 格式 as per tar &lt;= 1.12 pax POSIX 1003.1-2001 (pax) 格式 posix 等同于 pax ustar POSIX 1003.1-1988 (ustar) 格式 v7 old V7 tar 格式 --old-archive, --portability 等同于 --format=v7 --pax-option=关键字[[:]=值][,关键字[[:]=值]]... 控制 pax 关键字 --posix 等同于 --format=posix -V, --label=TEXT 创建带有卷名 TEXT 的归档；在列出/解压时，使用 TEXT 作为卷名的模式串 压缩选项: -a, --auto-compress 使用归档后缀名来决定压缩程序 -I, --use-compress-program=PROG 通过 PROG 过滤(必须是能接受 -d 选项的程序) -j, --bzip2 通过 bzip2 过滤归档 -J, --xz 通过 xz 过滤归档 --lzip 通过 lzip 过滤归档 --lzma 通过 lzma 过滤归档 --lzop --no-auto-compress 不使用归档后缀名来决定压缩程序 -z, --gzip, --gunzip, --ungzip 通过 gzip 过滤归档 -Z, --compress, --uncompress 通过 compress 过滤归档 本地文件选择: --add-file=FILE 添加指定的 FILE 至归档(如果名字以 - 开始会很有用的) --backup[=CONTROL] 在删除前备份，选择 CONTROL 版本 -C, --directory=DIR 改变至目录 DIR --exclude=PATTERN 排除以 PATTERN 指定的文件 --exclude-backups 排除备份和锁文件 --exclude-caches 除标识文件本身外，排除包含CACHEDIR.TAG 的目录中的内容 --exclude-caches-all 排除包含 CACHEDIR.TAG 的目录 --exclude-caches-under 排除包含 CACHEDIR.TAG 的目录中所有内容 --exclude-tag=FILE 除 FILE 自身外，排除包含 FILE 的目录中的内容 --exclude-tag-all=FILE 排除包含 FILE 的目录 --exclude-tag-under=FILE 排除包含 FILE 的目录中的所有内容 --exclude-vcs 排除版本控制系统目录 -h, --dereference 跟踪符号链接；将它们所指向的文件归档并输出 --hard-dereference 跟踪硬链接；将它们所指向的文件归档并输出 -K, --starting-file=MEMBER-NAME begin at member MEMBER-NAME when reading the archive --newer-mtime=DATE 当只有数据改变时比较数据和时间 --no-null 禁用上一次的效果 --null 选项 --no-recursion 避免目录中的自动降级 --no-unquote 不以 -T 读取的文件名作为引用结束 --null -T 读取以空终止的名字，-C 禁用 -N, --newer=DATE-OR-FILE, --after-date=DATE-OR-FILE 只保存比 DATE-OR-FILE 更新的文件 --one-file-system 创建归档时保存在本地文件系统中 -P, --absolute-names 不要从文件名中清除引导符‘/’ --recursion 目录递归(默认) --suffix=STRING 在删除前备份，除非被环境变量 SIMPLE_BACKUP_SUFFIX 覆盖，否则覆盖常用后缀(‘’) -T, --files-from=FILE 从 FILE 中获取文件名来解压或创建文件 --unquote 以 -T 读取的文件名作为引用结束(默认) -X, --exclude-from=FILE 排除 FILE 中列出的模式串 文件名变换: --strip-components=NUMBER 解压时从文件名中清除 NUMBER 个引导部分 --transform=EXPRESSION, --xform=EXPRESSION 使用 sed 代替 EXPRESSION 来进行文件名变换 文件名匹配选项(同时影响排除和包括模式串): --anchored 模式串匹配文件名头部 --ignore-case 忽略大小写 --no-anchored 模式串匹配任意‘/’后字符(默认对 exclusion 有效) --no-ignore-case 匹配大小写(默认) --no-wildcards 逐字匹配字符串 --no-wildcards-match-slash 通配符不匹配‘/’ --wildcards use wildcards (default) --wildcards-match-slash 通配符匹配‘/’(默认对排除操作有效) 提示性输出: --checkpoint[=NUMBER] 每隔 NUMBER 个记录显示进度信息(默认为 10 个) --checkpoint-action=ACTION 在每个检查点上执行 ACTION --full-time print file time to its full resolution --index-file=FILE 将详细输出发送至 FILE -l, --check-links 只要不是所有链接都被输出就打印信息 --no-quote-chars=STRING 禁用来自 STRING 的字符引用 --quote-chars=STRING 来自 STRING 的额外的引用字符 --quoting-style=STYLE 设置名称引用风格；有效的 STYLE 值请参阅以下说明 -R, --block-number 每个信息都显示归档内的块数 --show-defaults 显示 tar 默认选项 --show-omitted-dirs 列表或解压时，列出每个不匹配查找标准的目录 --show-transformed-names, --show-stored-names 显示变换后的文件名或归档名 --totals[=SIGNAL] 处理归档后打印出总字节数；当此 SIGNAL 被触发时带参数 - 打印总字节数；允许的信号为: SIGHUP，SIGQUIT，SIGINT，SIGUSR1 和 SIGUSR2；同时也接受不带 SIG 前缀的信号名称 --utc 以 UTC 格式打印文件修改时间 -v, --verbose 详细地列出处理的文件 --warning=KEYWORD 警告控制: -w, --interactive, --confirmation 每次操作都要求确认 兼容性选项: -o 创建归档时，相当于 --old-archive；展开归档时，相当于 --no-same-owner 其它选项: -?, --help 显示此帮助列表 --restrict 禁用某些潜在的有危险的选项 --usage 显示简短的用法说明 --version 打印程序版本长选项和相应短选项具有相同的强制参数或可选参数。除非以 --suffix 或 SIMPLE_BACKUP_SUFFIX设置备份后缀，否则备份后缀就是“~”。可以用 --backup 或 VERSION_CONTROL 设置版本控制，可能的值为： none, off 从不做备份 t, numbered 进行编号备份 nil, existing如果编号备份存在则进行编号备份，否则进行简单备份 never, simple 总是使用简单备份--quoting-style 选项的有效参数为: literal shell shell-always c c-maybe escape locale clocale此 tar 默认为:--format=gnu -f- -b20 --quoting-style=escape --rmt-command=/etc/rmt--rsh-command=/usr/bin/ssh 更多信息，可以从官网查看: https://www.gnu.org/software/tar. 常用命令案例 创建压缩文件target.tar，里面包括 file1 file2 file3:tar cf target.tar file1 file2 file3 创建gz压缩文件target.tar.gz，里面包括 file1 file2 file3:tar czf target.tar.gz file1 file2 file3 创建gz压缩文件target.tar.gz，使用-C参数，让压缩包中文件名不带全路径，而只有对应要打包的目录内的目录:tar czf target.tar.gz -C path/to/directory .例如打包tar zcf ./test3.tar.gz -C /Users/wangjun/WorkSpace/test ., 打包好的里面只有如下内容： 123wangjun@wangjundeMacBook-Pro WorkSpace % tar tvf test3.tar.gz drwxr-xr-x 0 wangjun staff 0 8 2 22:07 ./-rw-r--r-- 0 wangjun staff 2 8 2 22:07 ./test.txt 解压压缩文件：source.tar[.gz|.bz2|.xz]，到当前目录:tar xf source.tar[.gz|.bz2|.xz] 解压source.tar到目录directory下:tar xf source.tar -C directory 使用归档后缀名来决定压缩程序，创建压缩文件target.tar.xz，里面包括 file1 file2 file3:tar caf target.tar.xz file1 file2 file3 查看压缩文件source.tar中的内容:tar tvf source.tar 通配符可以用来解压于给定通配符匹配的一批文件，解压出压缩包source.tar中名字匹配*.html的文件:tar xf source.tar --wildcards &quot;*.html&quot; 解压出压缩包source.tar.gz中的指定文件，只需要将文件名按照以下方式将其放置在命令后面：tar -xzf source.tar.gz &quot;./new/cde.txt&quot; &quot;./new/abc.txt&quot; 解压出压缩包source.tar特定目录下的文件，并不保留对应目录结果，仅仅将文件抽取出来:tar xf source.tar source.tar/path/to/extract --strip-components=depth_to_strip 使用bzip2格式压缩压缩文件:tar cvfj archive.tar.tbz example.cpp &#x2F;&#x2F;其中: j = compress with bzip2, 相较于-z压缩率更高，但耗时更长 添加todo.txt到压缩文件（之前已经已经存在）archive.tar:tar rvf archive.tar todo.txt&#x2F;&#x2F;其中: r &#x3D; add file 创建压缩文件archive.tar,内容是当前目录中文，但是不包括文件&quot;folder&quot;和&quot;folder2&quot;:tar --exclude=&#39;./folder&#39; --exclude=&#39;./upload/folder2&#39; cfzv archive.tar . 使用 tar 命令进行定时备份:tar -zcvf optbackup-$(date +%Y-%m-%d).tgz /opt/ tar 命令中使用 -T 选项来指定需要归档压缩到文件列表，使用 -X 选项来指定包含要排除的文件列表：tar zcvf mybackup-$(date +%Y-%m-%d).tgz -T /root/tar-include -X /root/tar-exclude 使用split（split -b &lt;Size-in-MB&gt; &lt;tar-file-name&gt;.&lt;extension&gt; “prefix-name”）分割体积庞大的 tar 文件为多份小文件:split -b 6M big-tar-file.tgz bigfile-parts 不提取压缩包里文件的修改时间，以当前系统时间为准，给解压出的文件创建时间戳:tar mxf home.tar.gz&#x2F;&#x2F;加上 -m 参数后解压出的文件时间是当前系统时间 参考 Tar in Linux – Tar GZ, Tar File, Tar Directory, and Tar Compress Command Examples tldr 的 tar 命令 17 个 tar 命令实用示例","categories":[{"name":"Linux","slug":"Linux","permalink":"http://wangjstu.github.io/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://wangjstu.github.io/tags/Linux/"},{"name":"tar","slug":"tar","permalink":"http://wangjstu.github.io/tags/tar/"}]},{"title":"git stash 贮藏小技巧","slug":"Git-stash-useful-tricks","date":"2020-08-02T07:27:29.000Z","updated":"2020-08-02T07:27:29.000Z","comments":true,"path":"2020/08/02/Git-stash-useful-tricks/","link":"","permalink":"http://wangjstu.github.io/2020/08/02/Git-stash-useful-tricks/","excerpt":"","text":"目录 Git stash save Git stash list Git stash apply Git stash pop Git stash show Git stash branch Git stash clear Git stash drop 详解Git stash save Git stash with message贮藏(stash)时候增加备注信息，格式：git stash save “Your stash message”。 Stashing untracked files贮藏区(stash)未被git追踪的文件，格式：git stash save -u 或者 git stash save --include-untracked。 Git stash list git stash 实际是将变更放在一个提交对象中（Git commit object）中，存放在本地仓库中，并且存储是栈的形式。所以可以使用list命令查看stash中的所有记录，格式：git stash list。 Git stash apply 拿出贮藏区（stash）栈中的变更应用到当前的工作区，默认拿栈顶的stash@&#123;0&#125;，如果想要拿其他贮藏区的变更，可以使用命令：git stash apply stash@&#123;1&#125;。此操作后，贮藏区（stash）中不会将贮藏列表中使用的块移除。 Git stash pop 弹出贮藏区（stash）栈中的变更应用到当前的工作区，默认拿栈顶的stash@&#123;0&#125;，如果想要拿其他贮藏区的变更，可以使用命令：git stash pop stash@&#123;1&#125;。此操作后，贮藏区（stash）中会将贮藏列表中使用的块移除。 Git stash show git stash show显示贮藏区（stash）最后的一个的贮藏提交中的变更摘要信息，如果想要看详细变更比对信息，可以使用命令：git stash show -p，其中-p是 patch form 的意思。如果要看某个特定的贮藏区块，可以使用命令：git stash show stash@&#123;1&#125;。 Git stash branch git stash branch &lt;branch-name&gt; 命令使用贮藏区（stash）最后的一个的贮藏提交中的变更创建一个分支，分支名字是&lt;branch-name&gt;，此操作后，贮藏区（stash）中会将贮藏列表中使用的块移除。如果要拿特定的变更，可以使用命令：git stash branch &lt;name&gt; stash@&#123;1&#125;。 Git stash clear 移除贮藏区（stash）中所有存储的栈内容，此操作无法恢复。 Git stash drop git stash drop 命令会移除贮藏区（stash）中最顶块的贮藏块内容，不可恢复。如果要移除特定的块，可以使用命令：git stash drop stash@&#123;1&#125;。 参考 Useful tricks you might not know about Git stash","categories":[{"name":"Git","slug":"Git","permalink":"http://wangjstu.github.io/categories/Git/"}],"tags":[{"name":"Git","slug":"Git","permalink":"http://wangjstu.github.io/tags/Git/"},{"name":"stash","slug":"stash","permalink":"http://wangjstu.github.io/tags/stash/"}]},{"title":"error The following untracked working tree files would be overwritten by checkout","slug":"error-The-following-untracked-working-tree-files-would-be-overwritten-by-checkout","date":"2020-07-08T17:30:49.000Z","updated":"2020-07-08T17:30:49.000Z","comments":true,"path":"2020/07/09/error-The-following-untracked-working-tree-files-would-be-overwritten-by-checkout/","link":"","permalink":"http://wangjstu.github.io/2020/07/09/error-The-following-untracked-working-tree-files-would-be-overwritten-by-checkout/","excerpt":"","text":"问题今天在服务器上更新了一些代码文件，想着在本地也更新一下，之前在本地也编辑了部分，没有服务器上的全，要废弃了。到对应代码目录执行git pull origin master，蹦出了一堆错误： 123456789error: The following untracked working tree files would be overwritten by checkout: Learn_C_the_HARD_WAY/Exercise22/dbg.h Learn_C_the_HARD_WAY/Exercise22/ex22.c Learn_C_the_HARD_WAY/Exercise22/ex22.h Learn_C_the_HARD_WAY/Exercise22/ex22_main.cPlease move or remove them before you switch branches.Abortingfatal: Could not detach HEADFirst, rewinding head to replay your work on top of it... 通过错误提示可知，是由于一些untracked working tree files引起的问题。所以只要解决了这些untracked的文件就能解决这个问题。 解决方式：在对应目录下运行git clean -d -fx即可。可能很多人都不明白-d，-fx到底是啥意思，其实git clean -d -fx表示：删除 一些 没有 git add 的 文件； 12345678 git clean 参数 -n 显示将要删除的文件和目录； -x -----删除忽略文件已经对git来说不识别的文件 -d -----删除未被添加到git的路径中的文件 -f -----强制运行 git clean -n git clean -df git clean -f","categories":[{"name":"Git","slug":"Git","permalink":"http://wangjstu.github.io/categories/Git/"}],"tags":[{"name":"Git","slug":"Git","permalink":"http://wangjstu.github.io/tags/Git/"}]},{"title":"hexo blog 创建指导手册","slug":"hello-hexo-blog","date":"2020-07-05T14:20:21.000Z","updated":"2020-07-05T14:20:21.000Z","comments":true,"path":"2020/07/05/hello-hexo-blog/","link":"","permalink":"http://wangjstu.github.io/2020/07/05/hello-hexo-blog/","excerpt":"","text":"Github仓库建站 仓库建站 进入个人github Your Repositories Create a new repository 仓库名：wangjstu.github.io 点击创建 配置SSH keys cd ~&#x2F;.ssh ssh-keygen -t rsa -C “&#119;&#x61;&#110;&#x67;&#106;&#115;&#x74;&#117;&#64;&#103;&#x6d;&#x61;&#x69;&#108;&#46;&#x63;&#111;&#x6d;“ &#x2F;&#x2F;一路回车 ssh-add id_rsa &#x2F;&#x2F;添加秘钥 cat id_rsa.pub &#x2F;&#x2F;输出公钥，并添加到github上 完毕 初始化本地仓库 mkdir wangjstu.github.io &amp;&amp; cd wangjstu.github.io echo “# wangjstu.github.io” &gt;&gt; README.md git init git add README.md git commit -m “first commit” git remote add origin https://github.com/wangjstu/wangjstu.github.io.git git push -u origin master 验收 访问 https://wangjstu.github.io Node.js安装 安装node，有多种方法，我使用了第二种： 参考官网教程，但是这个方法，我因为墙放弃了 执行命令curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.35.3/install.sh | bash command -v nvm nvm install node 使用brew install node一键安装，我选择了这个方法 Hexo安装 安装hexo 执行命令 npm install -g hexo-cli 初始化blog 切换到wangjstu.github.io目录上一级，并执行命令hexo init blog，先将blog文件初始化到一个blog目录。建议先单独放一个目录，后面有用。 cd blog npm istall 本地测试 hexo g hexo server 打开浏览器，访问http://localhost:4000 就可以看到效果 目录略讲 node_modules: 依赖包 public：存放生成的页面 scaffolds：生成文章的一些模板 source：用来存放你的文章 themes：主题 _config.yml: 博客的配置文件 命令略讲解 hexo g &#x2F;&#x2F;生产静态文件 hexo server &#x2F;&#x2F;启动服务 hexo clean &#x2F;&#x2F;清除了你之前生成的东西 hexo generate &#x2F;&#x2F;顾名思义，生成静态文章，可以用 hexo g缩写 hexo deploy &#x2F;&#x2F;部署文章，可以用hexo d缩写 部署到github 执行命令 hexo clean cp -R blog&#x2F; wangjstu.github.io&#x2F; cd wangjstu.github.io npm install 编辑配置文件 _config.yml123456# Deployment## Docs: https://hexo.io/docs/deployment.htmldeploy: type: &#x27;git&#x27; repo: https://github.com/wangjstu/wangjstu.github.io.git branch: master npm install hexo-deployer-git –save &#x2F;&#x2F;一定要在wangjstu.github.io目录下执行，不如执行后面deploy命令会报错 执行以下命令部署 hexo clean hexo generate hexo deploy 访问https://wangjstu.github.io 查看效果 写文章及提交流程 hexo new “hello” 编辑source/_posts/hello.md hexo clean hexo g hexo d &#x2F;&#x2F;可以先hexo s，本地看下效果再执行提交 Hexo主题修改 修改主题流程 选择主题 按照自己主题的github上或官网文档进行修改 实际操作 我个人选择了主题 pure 安装主题1git clone https://github.com/cofess/hexo-theme-pure.git themes/pure 更新主题12cd themes/puregit pull 打开站点配置文件，找到theme字段，将其值更改为 pure12# vim wangjstu.github.io/_config.ymltheme: pure 安装主题需要的插件 npm install hexo-wordcount –save npm install hexo-generator-json-content –save npm install hexo-generator-feed –save npm install hexo-generator-sitemap –save npm install hexo-generator-baidu-sitemap –save npm install hexo-neat –save 主题配置 修改 wangjstu.github.io/_config.yml 1language: zh-CN 修改 wangjstu.github.io/themes/pure/_config.yml 双分支保存源文件 创建分支并上传blog源代码，执行以下命令： cd wangjstu.github.io rm -r themes&#x2F;pure&#x2F;.git hexo clean git add . &#x2F;&#x2F;一定要确保代码只有源代码文件，其他不要 git stash &#x2F;&#x2F;将源文件保存到stash git status &#x2F;&#x2F;这里检查一定要是干净的没有变化的 git checkout -b Hexo git stash pop git commit -m “add Hexo branch to save source file” git push -u origin Hexo:Hexo 到github上，将默认分支修改成Hexo 更换新工作环境后操作 初始化仓库 git clone https://github.com/wangjstu/wangjstu.github.io.git cd wangjstu.github.io npm install hexo npm install hexo-deployer-git –save 安装其他对应主题需要的插件 提交文章 hexo clean hexo g hexo d","categories":[{"name":"Hexo","slug":"Hexo","permalink":"http://wangjstu.github.io/categories/Hexo/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"http://wangjstu.github.io/tags/Hexo/"}]},{"title":"Hello World","slug":"hello-world","date":"2020-07-05T14:14:23.668Z","updated":"2020-07-05T14:14:23.668Z","comments":true,"path":"2020/07/05/hello-world/","link":"","permalink":"http://wangjstu.github.io/2020/07/05/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new &quot;My New Post&quot; More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[{"name":"Hexo","slug":"Hexo","permalink":"http://wangjstu.github.io/categories/Hexo/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"http://wangjstu.github.io/tags/Hexo/"}]},{"title":"Linux curl handbook","slug":"linux-curl-handbook","date":"2020-07-04T16:00:00.000Z","updated":"2020-07-04T16:00:00.000Z","comments":true,"path":"2020/07/05/linux-curl-handbook/","link":"","permalink":"http://wangjstu.github.io/2020/07/05/linux-curl-handbook/","excerpt":"","text":"简介Linux命令curl 可以被轻松地应用于 web 调试中，它们的好兄弟 wget 也是如此，或者也可以试试更潮的 httpie。本文罗列介绍curl相关知识点，以便更方便的使用。 linux curl本文使用的curl版本是： 1234[wangjstu@wangjstu ~]$ curl --versioncurl 7.29.0 (x86_64-redhat-linux-gnu) libcurl/7.29.0 NSS/3.28.4 zlib/1.2.7 libidn/1.28 libssh2/1.4.3Protocols: dict file ftp ftps gopher http https imap imaps ldap ldaps pop3 pop3s rtsp scp sftp smtp smtps telnet tftp Features: AsynchDNS GSS-Negotiate IDN IPv6 Largefile NTLM NTLM_WB SSL libz unix-sockets Linux curl 帮助文档：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319[wangjstu@wangjstu ~]$ curl --helpUsage: curl [options...] &lt;url&gt;//语法：curl [options] [url]Options: (H) means HTTP/HTTPS only, (F) means FTP only//PS: 以下Options中，后面是 (H) 表示只给 HTTP/HTTPS 使用, (F) 表示只给 FTP 使用 --anyauth Pick &quot;any&quot; authentication method (H) //--anyauth 选择 &quot;any&quot; 认证方法 (HTTP/HTTPS可用) -a, --append Append to target file when uploading (F/SFTP) //-a, --append 上传文件时，附加到目标文件 (FTP/SFTP可用) --basic Use HTTP Basic Authentication (H) //--basic 使用HTTP基础认证（参见文章末尾参考:HTTP Authentication）(HTTP/HTTPS可用) --cacert FILE CA certificate to verify peer against (SSL) //--cacert FILE CA 证书，用于每次请求认证 (SSL) --capath DIR CA directory to verify peer against (SSL) //--capath DIR CA 证书目录，用于每次请求认证 (SSL) -E, --cert CERT[:PASSWD] Client certificate file and password (SSL) //-E, --cert CERT[:PASSWD] 客户端证书文件及密码 (SSL) --cert-type TYPE Certificate file type (DER/PEM/ENG) (SSL) //--cert-type 证书文件类型 (DER/PEM/ENG) (SSL) --ciphers LIST SSL ciphers to use (SSL) //--ciphers LIST SSL 秘钥 (SSL) --compressed Request compressed response (using deflate or gzip) //--compressed 请求压缩响应 (使用 deflate 或 gzip) -K, --config FILE Specify which config file to read //-K, --config FILE 指定配置文件 --connect-timeout SECONDS Maximum time allowed for connection //--connect-timeout SECONDS 连接超时设置 -C, --continue-at OFFSET Resumed transfer offset //-C, --continue-at OFFSET 断点续传请求传输偏移量 -b, --cookie STRING/FILE String or file to read cookies from (H) //-b, --cookie STRING/FILE 设置请求头中Cookies，内容为后面传的字符串或从文件中读取的内容 (HTTP/HTTPS可用) -c, --cookie-jar FILE Write cookies to this file after operation (H) //-c, --cookie-jar FILE 请求完成后，返回头中 Cookies 值写入的文件位置 (HTTP/HTTPS可用) --create-dirs Create necessary local directory hierarchy //--create-dirs 创建必要的本地目录层次结构 --crlf Convert LF to CRLF in upload //--crlf 在上传时将 LF 转写为 CRLF --crlfile FILE Get a CRL list in PEM format from the given file //--crlfile FILE 从指定的文件获得PEM格式CRL列表 -d, --data DATA HTTP POST data (H) //-d, --data DATA http post请求数据 (HTTP/HTTPS可用) --data-ascii DATA HTTP POST ASCII data (H) //--data-ascii DATA ASCII编码HTTP POST数据 (HTTP/HTTPS可用) --data-binary DATA HTTP POST binary data (H) //--data-binary DATA binary 编码HTTP POST数据 (HTTP/HTTPS可用) --data-urlencode DATA HTTP POST data url encoded (H) //--data-urlencode DATA url 编码 HTTP POST 数据 (HTTP/HTTPS可用) --delegation STRING GSS-API delegation permission //--delegation STRING GSS-API 授权权限 --digest Use HTTP Digest Authentication (H) //--digest 使用HTTP Digest身份验证（参见文章末尾参考:HTTP Authentication）(HTTP/HTTPS可用) --disable-eprt Inhibit using EPRT or LPRT (F) //--disable-eprt 禁用EPRT或LPRT (FTP可用) --disable-epsv Inhibit using EPSV (F) //--disable-epsv 禁用EPSV (FTP可用) -D, --dump-header FILE Write the headers to this file //-D, --dump-header FILE 将请求返回头信息写入指定的文件 --egd-file FILE EGD socket path for random data (SSL) //--egd-file FILE 为随机数据(SSL)设置EGD socket路径 --engine ENGINGE Crypto engine (SSL). &quot;--engine list&quot; for list //--engine ENGINGE SSL加密引擎类型，使用&quot;--engine list&quot;获取可用类型 -f, --fail Fail silently (no output at all) on HTTP errors (H) //-f, --fail 连接失败时不显示HTTP错误详细信息，以curl错误显示 (HTTP/HTTPS可用) -F, --form CONTENT Specify HTTP multipart POST data (H) //-F, --form CONTENT 模拟 HTTP 表单数据提交（multipart POST） (HTTP/HTTPS可用) --form-string STRING Specify HTTP multipart POST data (H) //--form-string STRING 模拟 HTTP 表单数据提交 (HTTP/HTTPS可用) --ftp-account DATA Account data string (F) //--ftp-account DATA ftp帐户数据提交 (F) --ftp-alternative-to-user COMMAND String to replace &quot;USER [name]&quot; (F) //--ftp-alternative-to-user COMMAND 指定替换 &quot;USER [name]&quot; 的字符串 (F) --ftp-create-dirs Create the remote dirs if not present (F) //--ftp-create-dirs 如果远程不存相关目录，在则创建远程对应目录 (F) --ftp-method [MULTICWD/NOCWD/SINGLECWD] Control CWD usage (F) //--ftp-method [MULTICWD/NOCWD/SINGLECWD] 控制 CWD (F) --ftp-pasv Use PASV/EPSV instead of PORT (F) //--ftp-pasv 使用 PASV/EPSV 替换 PORT (F) -P, --ftp-port ADR Use PORT with given address instead of PASV (F) //-P, --ftp-port ADR 使用指定 PORT 及地址替换 PASV (F).使用端口地址，而不是使用PASV. --ftp-skip-pasv-ip Skip the IP address for PASV (F) //--ftp-skip-pasv-ip 跳过 PASV 的IP地址 (F) --ftp-pret Send PRET before PASV (for drftpd) (F) //--ftp-pret 在 PASV 之前发送 PRET (drftpd) (F) --ftp-ssl-ccc Send CCC after authenticating (F) //--ftp-ssl-ccc 认证之后发送 CCC (F) --ftp-ssl-ccc-mode ACTIVE/PASSIVE Set CCC mode (F) //--ftp-ssl-ccc-mode ACTIVE/PASSIVE 设置 CCC 模式 (F) --ftp-ssl-control Require SSL/TLS for ftp login, clear for transfer (F) //--ftp-ssl-control 登录时需要 SSL/TLS (F) -G, --get Send the -d data with a HTTP GET (H) //-G, --get 使用 HTTP GET 方法发送 -d 数据 (HTTP/HTTPS可用) -g, --globoff Disable URL sequences and ranges using &#123;&#125; and [] //-g, --globoff 禁用的 URL 队列 及范围使用 &#123;&#125; 和 [] -H, --header LINE Custom header to pass to server (H) //-H, --header LINE http请求服务端的自定义请求头 (HTTP/HTTPS可用) -I, --head Show document info only //-I, --head 仅显示返回响应文档头 -h, --help This help text //-h, --help 显示帮助文档 --hostpubmd5 MD5 Hex encoded MD5 string of the host public key. (SSH) //--hostpubmd5 MD5 将主机公钥的MD5字符串转为十六进制编码。（SSH） -0, --http1.0 Use HTTP 1.0 (H) //-0, --http1.0 使用 HTTP 1.0 (H) --ignore-content-length Ignore the HTTP Content-Length header //--ignore-content-length 忽略 HTTP Content-Length 头 -i, --include Include protocol headers in the output (H/F) //-i, --include 在输出中包含响应协议头 (H/F) -k, --insecure Allow connections to SSL sites without certs (H) //-k, --insecure 允许连接到 SSL 站点，而不使用证书 (H) --interface INTERFACE Specify network interface/address to use //--interface INTERFACE 指定网络接口／地址 -4, --ipv4 Resolve name to IPv4 address //-4, --ipv4 将域名解析为 IPv4 地址 -6, --ipv6 Resolve name to IPv6 address -6, --ipv6 将域名解析为 IPv6 地址 -j, --junk-session-cookies Ignore session cookies read from file (H) //-j, --junk-session-cookies 忽略从文件读取的会话cookie --keepalive-time SECONDS Interval between keepalive probes //--keepalive-time SECONDS keepalive 包间隔 --key KEY Private key file name (SSL/SSH) //--key KEY 私钥文件名 (SSL/SSH) --key-type TYPE Private key file type (DER/PEM/ENG) (SSL) //--key-type TYPE 私钥文件类型 (DER/PEM/ENG) (SSL) --krb LEVEL Enable Kerberos with specified security level (F) //--krb LEVEL 启用指定安全级别的 Kerberos (F) --libcurl FILE Dump libcurl equivalent code of this command line //--libcurl FILE 转储此命令行的libcurl等效代码 --limit-rate RATE Limit transfer speed to this rate //--limit-rate RATE 限制传输速度 -l, --list-only List only names of an FTP directory (F) //-l, --list-only 只列出FTP目录的名称 (FTP) --local-port RANGE Force use of these local port numbers //--local-port RANGE 强制使用的本地端口号 -L, --location Follow redirects (H) //-L, --location 跟踪重定向 (H) --location-trusted like --location and send auth to other hosts (H) //--location-trusted 类似 --location 并发送验证信息到其它主机 (H) -M, --manual Display the full manual //-M, --manual 显示详细帮助文档 --mail-from FROM Mail from this address //--mail-from FROM 设置邮件发送源地址 --mail-rcpt TO Mail to this receiver(s) //--mail-rcpt TO 设置邮件收件人(可用多人) --mail-auth AUTH Originator address of the original email //--mail-auth AUTH 原始电子邮件的发起人地址 --max-filesize BYTES Maximum file size to download (H/F) //--max-filesize BYTES 下载文件大小上限 (H/F) --max-redirs NUM Maximum number of redirects allowed (H) //--max-redirs NUM 最大重定向数 (H) -m, --max-time SECONDS Maximum time allowed for the transfer //-m, --max-time SECONDS 允许的最多传输时间 --metalink Process given URLs as metalink XML file //--metalink 将给定的URL作为metalink xml文件处理 --negotiate Use HTTP Negotiate Authentication (H) //--negotiate 使用HTTP协商身份验证（参见文章末尾参考:HTTP Authentication）(HTTP/HTTPS可用) -n, --netrc Must read .netrc for user name and password //-n, --netrc 必须从 .netrc 文件读取用户名和密码 --netrc-optional Use either .netrc or URL; overrides -n //--netrc-optional 使用 .netrc 或 URL; 将重写 -n 参数 --netrc-file FILE Set up the netrc filename to use //--netrc-file FILE 设置要使用的 netrc 文件名 -N, --no-buffer Disable buffering of the output stream //-N, --no-buffer 禁用输出流的缓存 --no-keepalive Disable keepalive use on the connection //--no-keepalive 禁用 connection 的 keepalive --no-sessionid Disable SSL session-ID reusing (SSL) //--no-sessionid 禁止重复使用 SSL session-ID (SSL) --noproxy List of hosts which do not use proxy //--noproxy 不使用代理的主机列表 --ntlm Use HTTP NTLM authentication (H) //--ntlm 使用HTTP NTLM验证（参见文章末尾参考:HTTP Authentication）(HTTP/HTTPS可用) -o, --output FILE Write output to &lt;file&gt; instead of stdout //-o, --output FILE 将输出写入文件，而非 stdout --pass PASS Pass phrase for the private key (SSL/SSH) //--pass PASS 传递给私钥的短语 (SSL/SSH) --post301 Do not switch to GET after following a 301 redirect (H) //--post301 在 301 重定向后不要切换为 GET 请求 (HTTP/HTTPS可用) --post302 Do not switch to GET after following a 302 redirect (H) //--post302 在 302 重定向后不要切换为 GET 请求 (HTTP/HTTPS可用) --post303 Do not switch to GET after following a 303 redirect (H) //--post303 在 303 重定向后不要切换为 GET 请求 (HTTP/HTTPS可用) -#, --progress-bar Display transfer progress as a progress bar //-#, --progress-bar 以进度条显示传输进度 --proto PROTOCOLS Enable/disable specified protocols //--proto PROTOCOLS 启用/禁用 指定的协议 --proto-redir PROTOCOLS Enable/disable specified protocols on redirect //--proto-redir PROTOCOLS 在重定向上 启用/禁用 指定的协议 -x, --proxy [PROTOCOL://]HOST[:PORT] Use proxy on given port //-x, --proxy [PROTOCOL://]HOST[:PORT] 指定代理端口及地址 --proxy-anyauth Pick &quot;any&quot; proxy authentication method (H) //--proxy-anyauth 在代理上使用 &quot;any&quot; 认证方法 (HTTP/HTTPS可用) --proxy-basic Use Basic authentication on the proxy (H) //--proxy-basic 在代理上使用 Basic 认证 (HTTP/HTTPS可用) --proxy-digest Use Digest authentication on the proxy (H) //--proxy-digest 在代理上使用 Digest 认证 (HTTP/HTTPS可用) --proxy-negotiate Use Negotiate authentication on the proxy (H) //--proxy-negotiate 在代理上使用 Negotiate 认证 (HTTP/HTTPS可用) --proxy-ntlm Use NTLM authentication on the proxy (H) //--proxy-ntlm 在代理上使用 NTLM 认证 (HTTP/HTTPS可用) -U, --proxy-user USER[:PASSWORD] Proxy user and password //-U, --proxy-user USER[:PASSWORD] 代理用户名及密码 --proxy1.0 HOST[:PORT] Use HTTP/1.0 proxy on given port //--proxy1.0 HOST[:PORT] 使用指定地址及端口的HTTP/1.0的代理 -p, --proxytunnel Operate through a HTTP proxy tunnel (using CONNECT) //-p, --proxytunnel 使用HTTP代理隧道 (用于 CONNECT) --pubkey KEY Public key file name (SSH) //--pubkey KEY 指定请求的公钥文件名 -Q, --quote CMD Send command(s) to server before transfer (F/SFTP) //-Q, --quote CMD 在传输开始前向服务器发送命令 (F/SFTP) --random-file FILE File for reading random data from (SSL) //--random-file FILE 设置读取随机数据的文件 (SSL) -r, --range RANGE Retrieve only the bytes within a range //-r, --range RANGE 仅检索范围内的字节 --raw Do HTTP &quot;raw&quot;, without any transfer decoding (H) //--raw 使用原始HTTP传输，而不使用编码 (HTTP/HTTPS可用) -e, --referer Referer URL (H) //-e, --referer Referer URL (HTTP/HTTPS可用) -J, --remote-header-name Use the header-provided filename (H) //-J, --remote-header-name 从远程文件读取头信息 (HTTP/HTTPS可用) -O, --remote-name Write output to a file named as the remote file //-O, --remote-name 请求远程文件时，将请求返回内容以远程文件名保存到本地，如果没有则报错 --remote-name-all Use the remote file name for all URLs //--remote-name-all 将请求的URL设置为请求远程文件名 -R, --remote-time Set the remote file&#x27;s time on the local output //-R, --remote-time 将远程文件的时间设置在本地输出上 -X, --request COMMAND Specify request command to use //-X, --request COMMAND 使用指定的请求方法(GET POST等) --resolve HOST:PORT:ADDRESS Force resolve of HOST:PORT to ADDRESS //--resolve HOST:PORT:ADDRESS 强制设置请求头中的HOST为对应的ip地址+端口 --retry NUM Retry request NUM times if transient problems occur //--retry NUM 出现问题时的重试次数 --retry-delay SECONDS When retrying, wait this many seconds between each //--retry-delay SECONDS 重试时的间隔时长 --retry-max-time SECONDS Retry only within this period //--retry-max-time SECONDS 仅在指定时间段内重试 -S, --show-error Show error. With -s, make curl show errors when they occur //-S, --show-error 显示错误. 在选项 -s 中，当 curl 出现错误时将显示 -s, --silent Silent mode. Don&#x27;t output anything //-s, --silent Silent模式。不输出任务内容 --socks4 HOST[:PORT] SOCKS4 proxy on given host + port //--socks4 HOST[:PORT] 使用指定的 host + port 作为 SOCKS4 代理 --socks4a HOST[:PORT] SOCKS4a proxy on given host + port //--socks4a HOST[:PORT] 使用指定的 host + port 作为 socks4a 代理 --socks5 HOST[:PORT] SOCKS5 proxy on given host + port //--socks5 HOST[:PORT] 使用指定的 host + port 作为 socks5 代理 --socks5-hostname HOST[:PORT] SOCKS5 proxy, pass host name to proxy //--socks5-hostname HOST[:PORT] 通过对应的hostname(地址+端口)实现SOCKS5代理 --socks5-gssapi-service NAME SOCKS5 proxy service name for gssapi //--socks5-gssapi-service NAME SOCKS5代理GSSAPI服务名称 --socks5-gssapi-nec Compatibility with NEC SOCKS5 server //--socks5-gssapi-nec 与NEC Socks5服务器兼容 -Y, --speed-limit RATE Stop transfers below speed-limit for &#x27;speed-time&#x27; secs //-Y, --speed-limit RATE 在指定限速情况下，指定相应时间之后停止传输 -y, --speed-time SECONDS Time for trig speed-limit abort. Defaults to 30 //-y, --speed-time SECONDS 指定时间之后触发限速. 默认 30 --ssl Try SSL/TLS (FTP, IMAP, POP3, SMTP) //--ssl 尝试 SSL/TLS (FTP, IMAP, POP3, SMTP) --ssl-reqd Require SSL/TLS (FTP, IMAP, POP3, SMTP) //--ssl-reqd 需要 SSL/TLS (FTP, IMAP, POP3, SMTP) -2, --sslv2 Use SSLv2 (SSL) //-2, --sslv2 使用 SSLv2 (SSL) -3, --sslv3 Use SSLv3 (SSL) //-3, --sslv3 使用 SSLv3 (SSL) --ssl-allow-beast Allow security flaw to improve interop (SSL) //--ssl-allow-beast 允许安全缺陷改进互操作 (SSL) --stderr FILE Where to redirect stderr. - means stdout //--stderr FILE 重定向 stderr 的文件位置, 默认 stdout --tcp-nodelay Use the TCP_NODELAY option //--tcp-nodelay 使用 TCP_NODELAY 选项 -t, --telnet-option OPT=VAL Set telnet option //-t, --telnet-option OPT=VAL 设置 telnet 选项 --tftp-blksize VALUE Set TFTP BLKSIZE option (must be &gt;512) //--tftp-blksize VALUE 设备 TFTP BLKSIZE 选项 (必须 &gt;512) -z, --time-cond TIME Transfer based on a time condition //-z, --time-cond TIME 基于时间条件的传输 -1, --tlsv1 Use =&gt; TLSv1 (SSL) //-1, --tlsv1 使用TLSv1 (SSL) --tlsv1.0 Use TLSv1.0 (SSL) //--tlsv1.0 使用TLSv1.0 (SSL) --tlsv1.1 Use TLSv1.1 (SSL) //--tlsv1.1 使用TLSv1.1 (SSL) --tlsv1.2 Use TLSv1.2 (SSL) //--tlsv1.2 使用TLSv1.2 (SSL) --trace FILE Write a debug trace to the given file //--trace FILE 将 debug 信息写入指定的文件 --trace-ascii FILE Like --trace but without the hex output //--trace-ascii FILE 类似 --trace 但使用16进度输出 --trace-time Add time stamps to trace/verbose output //--trace-time 向 trace/verbose 输出添加时间戳 --tr-encoding Request compressed transfer encoding (H) //--tr-encoding 请求压缩传输编码 (HTTP/HTTPS可用) -T, --upload-file FILE Transfer FILE to destination //-T, --upload-file FILE 将文件传输（上传）到目的地址 --url URL URL to work with //--url URL 指定所使用的 URL -B, --use-ascii Use ASCII/text transfer //-B, --use-ascii 使用 ASCII/text 传输 -u, --user USER[:PASSWORD] Server user and password //-u, --user USER[:PASSWORD] 指定服务器认证用户名、密码 --tlsuser USER TLS username //--tlsuser USER TLS 用户名 --tlspassword STRING TLS password //--tlspassword STRING TLS 密码 --tlsauthtype STRING TLS authentication type (default SRP) //-tlsauthtype STRING TLS 认证类型 (默认 SRP) --unix-socket FILE Connect through this UNIX domain socket //--unix-socket FILE 指定 UNIX socket 域连接 -A, --user-agent STRING User-Agent to send to server (H) //-A, --user-agent STRING 设置要发送到服务器的 User-Agent (HTTP/HTTPS可用) -v, --verbose Make the operation more talkative //-v, --verbose 显示详细操作信息 -V, --version Show version number and quit //-V, --version 显示版本号并退出 -w, --write-out FORMAT What to output after completion //-w, --write-out FORMAT 用于在一次完整且成功的操作后输出指定格式的内容到标准输出 --xattr Store metadata in extended file attributes //--xattr 将元数据存储在扩展文件属性中 -q If used as the first parameter disables .curlrc //-q 如果作为第一个参数, .curlrc 中的设置无效。 curl会在程序启动时会自动尝试读取用户家目录中的.curlrc文件。 命令速记[译]基础案例 请求个人blog主页 1curl https://wangjstu.github.io/ 请求funet的ftp的README文件 1curl ftp://ftp.funet.fi/README 通过端口8000获取某主页 1curl http://www.weirdserver.com:8000/ 获取ftp站点的目录列表 1curl ftp://ftp.funet.fi/ 通过字典查询单词 123456789//Aliases for ‘m’ are ‘match’ and ‘find’, and aliases for ‘d’ are ‘define’ and ‘lookup’# 查询bash单词的含义curl dict://dict.org/d:bash # 列出所有可用词典curl dict://dict.org/show:db# 在foldoc词典中查询bash单词的含义curl dict://dict.org/d:bash:foldoc# 查看curl的定义curl dict://dict.org/m:curl 一次请求两个页面 1curl ftp://cool.haxx.se/ http://www.weirdserver.com:8000/ 获取ftps上文件 1curl ftps://files.are.secure.com/secrets.txt 获取ftps上文件 1234#直接使用ftps协议curl ftps://files.are.secure.com/secrets.txt#使用ftp协议，并增加ssl选项curl --ftp-ssl ftp://files.are.secure.com/secrets.txt 通过ssh协议(SFTP)结合账号名获取一个文件 1curl -u username sftp://example.com/etc/issue 通过ssh协议(SCP)结合私钥获取一个文件 1234#密码不保护输入方式curl -u username: --key ~/.ssh/id_rsa scp://example.com/~/file.txt#密码保护方式curl -u username: --key ~/.ssh/id_rsa --pass private_key_password scp://example.com/~/file.txt 访问已个IPV6站点下载文件 1curl &quot;http://[2001:1890:1112:1::20]/&quot; 访问SMB站点下载文件 1curl -u &quot;domain\\username:passwd&quot; smb://server.example.com/share/file.txt 下载保存到文件(Download to a File) 访问某站点主页并将主页另存为到本地 1curl -o thatpage.html http://www.netscape.com/ 访问某站点主页并将主页内容按URL最后文件名报错在本地，如果没有文件名，则报错 123curl -O http://www.netscape.com/index.html#同时下载2个curl -O www.haxx.se/index.html -O curl.haxx.se/download.html 使用普通认证(账号密码 Using Passwords) FTP 1234使用URL中传输账号名密码的格式请求认证curl ftp://name:passwd@machine.domain:port/full/path/to/file或者使用 -u 参数curl -u name:passwd ftp://machine.domain:port/full/path/to/file FTPS 1更加推荐通过使用FTP：//和--ftp-ssl选项完成。 SFTP&#x2F;SCP 1选项--key表示私钥，--pass表示密码，--pubkey表示公钥 HTTP 12345支持以下两种方式: curl http://name:passwd@machine.domain/full/path/to/file curl -u name:passwd http://machine.domain/full/path/to/file第一种方式会由于URL规范中不能包含用户名和密码，虽然curl支持，但是通过代理时无法正常使用。HTTP提供了许多不同的身份验证方法，curl支持以下几种方法：Basic, Digest, NTLM and Negotiate (SPNEGO)。默认curl是Basic模式，可以使用--anyauth来与服务器选用一种更安全的方式。 HTTPS 123456最常与私人证书一起使用：curl -k https://www.thesitetoauthenticate.com/test -v –key key.pem –cacert ca.pem –cert client.pemcurl -X GET -H &quot;Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpYXQiOjE1MjgwMTY5MjIsImlkIjowLCJuYmYiOjE1MjgwMTY5MjIsInVzZXJuYW1lIjoiYWRtaW4ifQ.LjxrK9DuAwAzUD8-9v43NzWBN7HXsSLfebw92DKd1JQ&quot; -H &quot;Content-Type: application/json&quot; https://127.0.0.1:8081/v1/user --cacert conf/server.crt --cert conf/server.crt --key conf/server.key 代理(proxy)curl支持HTTP及SOCKS代理，但是对FTP协议没有特别支持，不过可以HTTP及SOCKS的代理去向FTP传输文件。 12345curl -x my-proxy:888 ftp://ftp.leachsite.com/README //代理名字叫my-proxy，端口是888curl -u user:passwd -x my-proxy:888 http://www.get.this/ //使用需要账户的代理curl -U user:passwd -x my-proxy:888 http://www.get.this/curl --noproxy localhost,get.this -x my-proxy:888 http://www.get.this/ //本地请求不适用代理，可以用逗号分隔。使用--proxy1.0 (默认是用--proxy或-x)特指适用http1.0代理，--socks4 and --socks5特指使用SOCKS4 and SOCKS5代理。curl -u &quot;username@ftp.server Proxy-Username:Remote-Pass&quot; --ftp-account Proxy-Password --upload-file local-file ftp://my-ftp.proxy.server:21/remote/upload/path/ //ftp使用代理上传文件 断点续传(Ranges)http 1.1支持断点续传，可以一部分一部分下载，curl使用 -r 参数。 123curl -r 0-99 http://www.get.this/ //获取前一百个字节curl -r -500 http://www.get.this/ //获取最后500个字节curl -r 0-99 ftp://www.get.this/README //获取ftp中前100个字节，FTP中必须传起始位置截止位置 上传文件(Uploading[FTP&#x2F;FTPS&#x2F;SFTP&#x2F;SCP&#x2F;HTTP])1234567curl -T - ftp://ftp.upload.com/myfile //将标准输入的数据全部上传到ftpcurl -T uploadfile -u user:passwd ftp://ftp.upload.com/myfile //上传文件名为uploadfile到ftp，在ftp上命名为myfile，并使用用户名和密码curl -T uploadfile -u user:passwd ftp://ftp.upload.com/ //上传文件名为uploadfile到ftp，在ftp上名字同本地相同curl -T localfile -a ftp://ftp.upload.com/remotefile //上唇本地文件localfile，追加到ftp上名为remotefile的文件中curl --proxytunnel -x proxy:port -T localfile ftp.upload.com //使用允许上传文件的代理进行文件上传curl -T file.txt -u &quot;domain\\username:passwd&quot; smb://server.example.com/share/ //SMB、SMBS上传文件curl -T - http://www.upload.com/myfile //http上传标准输入中的全部数据，这是PUT请求 debug追踪(Verbose &#x2F; Debug)12curl -v ftp://ftp.upload.com/ //-v参数可以用来查看curl请求失败时，server端返回的详细错误信息curl --trace trace.txt www.haxx.se //--trace or --trace-ascii可以获取到更详细的追踪信息，并保存到本地的trace.txt文件中 查看返回头信息(Detailed Information)12curl 可以使用 -I/--head 展示HTTP/FTP的头信息（仅展示头信息）。或使用-i/--include展示头信息及body。另外curl支持-D/--dump-header将body与头信息分开，头信息存储在单独制定的文件中，body返回展示。可以用来临时保存cookie等头信息。curl --dump-header headers.txt curl.haxx.se //头信息保存在headers.txt POST(HTTP)123456789101112131415-d 支持 application/x-www-form-urlencoded mime-type表单传输：curl -d &quot;name=Rafael%20Sagula&amp;phone=3320780&quot; http://www.where.com/guest.cgi //使用-d传输post参数，切记post参数要urlencode-F 支持 multipart/form-data 类型，如上传文件：curl -F &quot;coolfiles=@fil1.gif;type=image/gif,fil2.txt,fil3.html&quot; http://www.post.com/postit.cgi //上传文件，并使用@fil1.gif从文件中读取内容，后面的;type=&lt;mime type&gt; 指定文件类型，本例子上传了三个文件fil1.gif，fil2.txt，fil3.html。可以使用@前缀来制定提交的内容为一个文件，也可以使用&lt;符号来提交文件中的内容。另外-F支持多个字段传输，多文件传输：curl -F &quot;file=@cooltext.txt&quot; -F &quot;yourname=Daniel&quot; -F &quot;filedescription=Cool text file with cool text inside&quot; http://www.post.com/postit.cgicurl -F &quot;pictures=@dog.gif,cat.gif&quot; $URLcurl -F &quot;docpicture=@dog.gif&quot; -F &quot;catpicture=@cat.gif&quot; $URL另外可以使用 --form-string Referrer1curl -e www.coolsite.com http://www.showme.com/ //curl可以使用-e参数指定http请求头中的referred值 客户端请求标志头信息(User Agent)123curl -A &#x27;Mozilla/3.0 (Win95; I)&#x27; http://www.nationsbank.com/ //-A或者--user-agent标志请求的客户端的标志头信息等同于 curl -H &#x27;User-Agent: Mozilla/3.0 (Win95; I)&#x27; https://www.nationsbank.com/ Cookies12345HTTP是无状态的，为了解决这个问题，一般HTTP服务端返回cookie信息格式如下：Set-Cookie: sessionid=boo123; path=&quot;/foo&quot;;用于对客户端进行唯一标志状态。传输cookie可以使用以下方法：curl -b &quot;name=Daniel&quot; www.sillypage.comcurl -b headersfile www.example.com //其中headersfile来自 curl --dump-header headers www.example.com， 或者使用-c参数，将cookie写入一个txt文本 curl -c cookies.txt www.example.comcurl -b cookies.txt -c cookies.txt www.example.com //保存cookie，并及时使用cookiecurl -L -b empty.txt www.example.com //请求跟随服务器的重定向，并带上cookie。 进度信息(Progress Meter)123curl请求时候经常返回如下信息% Total % Received % Xferd Average Speed Dload Average Speed Upload Time Total Time Current Time Left CURR.Speed0 151M 0 38608 0 0 9406 0 4:41:43 0:00:04 4:41:39 9287 以上信息表示： 123456789101112% - 整体传输完成百分比Total - 整体传输的大小% - 下载完成百分比Received - 当前已下载的字节数% - 上传完成百分比Xferd - 当前已上传的字节数Average Speed Dload - 平均下载速度Average Speed Upload - 平均上传速度Time Total - 预计完成全部传输所需的时间Time Current - 当前所消耗的时间Time Left - 预计完成剩余传输所需的时间Curr.Speed - 最近5秒内平均传输速度(传输最开始5秒，该值是基于线路理论上的速度来计算的) 限速请求(Speed Limit)12345curl -Y 3000 -y 60 www.far-away-site.com //如果速度小于300bytes/s，并持续1分钟，则终止curlcurl -m 1800 -Y 3000 -y 60 www.far-away-site.com //前面的限制，另外加一个限制，在30分钟时终止请求curl --limit-rate 10K www.far-away-site.com //限制请求速度在10kb/s以下curl --limit-rate 10240 www.far-away-site.com //同上，限制请求速度在10kb/s以下curl -T upload --limit-rate 1M ftp://uploadshereplease.com //限制上传文件的速度在1Mb/s以下 配置信息(Config File)curl 请求时会从本地home目录中的.curlrc （windows中是 _curlrc）中读取一些共用的配置信息，如proxy等: 123456# We want a 30 minute timeout:-m 1800#. .. and we use a proxy for all accesses:proxy = proxy.our.domain.com:8080# default url to geturl = &quot;http://help.with.curl.com/curlhelp.html&quot; 如果要阻止使用配置文件，使用-q参数：curl -q www.thatsite.com另外可以使用-K&#x2F;–config来读取一些配置从stdin中：echo &quot;user = user:passwd&quot; | curl -K - http://that.secret.site.com 头信息(Extra Headers)可以使用-H参数传输头信息到Server端，如curl -H &quot;X-you-and-me: yes&quot; www.love.comcurl -H &quot;Host:&quot; www.server.com 会发出异常的头信息。 FTP and Path Names12curl ftp://user:passwd@my.site.com/README //从ftp的服务主目录下载README，相对地址curl ftp://user:passwd@my.site.com//README //从ftp的服务器的根目录下下载README，绝对地址 SFTP and SCP and Path Names1curl -u $USER sftp://home.example.com/~/.bashrc //sftp: 和 scp: URLs显示的是绝对地址，下载home目录中的文件 FTP and Firewalls123curl -P - ftp.download.com //使用默认网卡下载,即为使用端口地址,而不是使用PASV curl -P le0 ftp.download.com //通过网卡le0下载ftp文件curl -P 192.168.0.10 ftp.download.com //将本地IP置为 192.168.0.10 去下载 Network Interface12curl --interface eth0:1 http://www.netscape.com/ //使用网卡eth0,端口1请求curl --interface 192.168.1.10 http://www.netscape.com/ //使用网络地址 192.168.1.10 来请求 HTTPS安装了TLS(传输层安全)库之后，curl可以请求一般的https站点： 1curl https://www.secure-site.com 另外，还支持客户端使用私有证书请求，但是请求中证书必须是PEM格式。如下是请求案例 1234curl -E /path/to/cert.pem:password https://secure.site.com/ //使用密码+pem证书请求。这类请求如果未填写密码，则在收数据前会收到提示，填写密码curl -2 https://secure.site.com/ //部分站点需要特殊指定SSL或TLS版本， -3, -2 , -1 代表 SSLv3, SSLv2 , TLSv1curl -k -v –key key.pem –cacert ca.pem –cert client.pem https://www.thesitetoauthenticate.com/test curl -k -v -4 --tlsv1.2 --cert client.pem --key key.pem https://www.thesitetoauthenticate.com/test 一般申请的证书都是PIE((Personal Information Exchange)，可以通过以下方式转换为pem： 1234567891) 第一类：密码+证书使用openssl转换：openssl pkcs12 -in abcd.pfx -out abcd.pem根据提示输入口令及密码(Enter a passphrase and a password)，这类应用于密码+证书的。2) 第二类：私钥、证书等三个客户端使用的文件：openssl pkcs12 -in abcd.pfx -out ca.pem -cacerts -nokeysopenssl pkcs12 -in abcd.pfx -out client.pem -clcerts -nokeysopenssl pkcs12 -in abcd.pfx -out key.pem -nocerts3) 使用方法:curl -k https://www.thesitetoauthenticate.com/test -v –key key.pem –cacert ca.pem –cert client.pem: 持续传输(Resuming File Transfers)123curl -C - -o file ftp://ftp.server.com/path/file //继续从ftp下载curl -C - -T file ftp://ftp.server.com/path/file //继续上传文件到ftpcurl -C - -o file http://www.server.com/ //从http服务端继续下载 Time ConditionsIf-Modified-Since与If-Unmodified-Since常用语静态文件缓存或断点续传下载等。先了解一下两者的区别： If-Unmodified-Since HTTP协议中的 If-Unmodified-Since 消息头用于请求之中，使得当前请求成为条件式请求：只有当资源在指定的时间之后没有进行过修改的情况下，服务器才会返回请求的资源，或是接受 POST 或其他 non-safe 方法的请求。如果所请求的资源在指定的时间之后发生了修改，那么会返回 412 (Precondition Failed) 错误。 常见的应用场景有两种： 与 non-safe 方法如 POST 搭配使用，可以用来优化并发控制，例如在某些wiki应用中的做法：假如在原始副本获取之后，服务器上所存储的文档已经被修改，那么对其作出的编辑会被拒绝提交。与含有 If-Range 消息头的范围请求搭配使用，用来确保新的请求片段来自于未经修改的文档。 If-Modified-Since If-Modified-Since 是一个条件式请求首部，服务器只在所请求的资源在给定的日期时间之后对内容进行过修改的情况下才会将资源返回，状态码为 200 。如果请求的资源从那时起未经修改，那么返回一个不带有消息主体的 304 响应，而在 Last-Modified 首部中会带有上次修改时间。 不同于 If-Unmodified-Since, If-Modified-Since 只可以用在 GET 或 HEAD 请求中。 当与 If-None-Match 一同出现时，它（If-Modified-Since）会被忽略掉，除非服务器不支持 If-None-Match。 最常见的应用场景是来更新没有特定 ETag 标签的缓存实体。 CURL也支持： 123curl -z local.html http://remote.server.com/remote.html //如果服务器端文件更新则下载curl -z -local.html http://remote.server.com/remote.html //如果本地文件较新，则下载远端curl -z &quot;Jan 12 2012&quot; http://remote.server.com/remote.html //2012年1月12日后更新就下载 DICT12345678别名m的意思是匹配（match)并查找(find)，而别名d是定义(define)并查找(lookup)的意思curl dict://dict.org/m:curlcurl dict://dict.org/d:heisenbug:jargoncurl dict://dict.org/d:daniel:web1913curl dict://dict.org/find:curlcurl dict://dict.org/show:db //列出所有可用词典curl dict://dict.org/show:stratcurl dict://dict.org/d:bash:foldoc //在foldoc词典中查询bash单词的含义 轻量目录访问协议(LDAP)linux上需要安装OpenLDAP库，windows上需要安装WinLDAP。LDAP默认用LDAPv3，当失败时有机制调用LDAPv2。 1234curl -B &quot;ldap://ldap.frontec.se/o=frontec??sub?mail=*sth.frontec.se&quot;curl -u user:passwd &quot;ldap://ldap.frontec.se/o=frontec??sub?mail=*&quot;curl &quot;ldap://user:passwd@ldap.frontec.se/o=frontec??sub?mail=*&quot;curl --ntlm &quot;ldap://user:passwd@ldap.frontec.se/o=frontec??sub?mail=*&quot; 环境变量(Environment Variables)curl会从环境变量中获取:http_proxy, HTTPS_PROXY, FTP_PROXY代理信息。可以通过ALL_PROXY设置所有都默认使用的代理，可以使用NO_PROXY设置不适用的代理。使用-x&#x2F;–proxy 会覆盖这些环境变量。linux系统设置http&#x2F;https proxy的方法，在文件 .bashrc 中添加，或者在&#x2F;etc&#x2F;bashrc或者&#x2F;etc&#x2F;profile中添加如下环境变量： 1234567export http_proxy=proxy_addr:portexport ftp_proxy=proxy_addr:portexport https_proxy=proxy_addr:port如:export http_proxy=&quot;192.168.0.1:8080&quot;export no_proxy=&#x27;a.test.com,127.0.0.1,2.2.2.2&#x27;export http_proxy=http://easwy:123456@192.168.1.1:8080 //如果密码或用户名中有特殊字符，例如&lt;，可以用 \\&lt; 来转义 netrc文件.netrc用于设置自动登录时所需要的帐号信息。下面是一个常用的”netrc”文件的内容： 12machine somehost.com login username password passwddefault login username password passwd curl支持-n&#x2F;–netrc 和 –netrc-optional 命令参数指向使用netrc。 自定义输出(Custom Output)-w&#x2F;–write-out参数用于在一次完整且成功的操作后输出指定格式的内容到标准输出。 123curl -w &#x27;We downloaded %&#123;size_download&#125; bytes\\n&#x27; www.baidu.com //自定义输出下载了多大的文件curl -s -m 10 -o /dev/null -w %&#123;http_code&#125; https://www.baidu.com //取URL返回状态码 支持参数参见该文档 Kerberos FTP传输1curl --krb private ftp://krb4site.com -u username:fakepwd TELNET12curl telnet://remote.server.com //向远端服务器访问，将stdin输入的数据传到远端，可以用-o将stdout输出到文件，-N/--no-buffer关闭输出curl -tTTYPE=vt100 telnet://remote.server.com //使用-t选项将选项传递给telnet协议协商。要告诉服务器我们使用vt100终端 持久连接(Persistent Connections)在一个命令行中指定多个文件将使curl按指定的顺序依次传输所有文件。libcurl将尝试为传输使用持久连接，这样到同一主机的第二个传输就可以使用在前一个传输中已经启动并处于打开状态的连接。这大大减少了除了第一次传输之外的所有连接时间，并且更好地利用了网络。请注意，curl不能对在随后的curl调用中使用的传输使用持久连接。如果使用相同的主机，尝试在相同的命令行中填充尽可能多的url，因为这会使传输更快。如果使用HTTP代理进行文件传输，实际上所有传输都是持久的。 单命令多请求(Multiple Transfers With A Single Command Line)12curl -O http://url.com/file.txt ftp://ftp.com/moo.exe -o moo.jpg //第一个请求使用-O将获取到的文件保存到本地，命名为file.txt，第二个请求用-o ，另存为moo.jpgcurl -T local1 ftp://ftp.com/moo.exe -T local2 ftp://ftp.com/moo2.txt //分别上传文件到两个ftp IPv61234curl -g http://[2001:1890:1112:1::20]/overview.htmlcurl -6 -d post &#x27;http://2001:0:db8:1111:0:0:0:11:8091/&#x27; //-4表示ipv4，-6表示ipv6curl -g -6 &#x27;http://[fe80::3ad1:35ff:fe08:cd%eth0]:80/&#x27; //telnet -6 fe80::3ad1:35ff:fe08:cd%eth0 80curl --interface eth0 -g -6 &#x27;http://[2606:2800:220:1:248:1893:25c8:1946]:80/index.html&#x27; -H &#x27;Host: www.example.com&#x27; Metalink12curl --metalink http://www.example.com/example.metalinkcurl --metalink file://example.metalink 常见问题记官方常见问题-F与-d区别 当form表单以enctype&#x3D;multipart&#x2F;form-data提交时，使用-F，常见场景是上传文件时, 1234567891011121314151617181920212223242526&lt;form action=&quot;submit.cgi&quot; method=&quot;post&quot; enctype=&quot;multipart/form-data&quot;&gt; Name: &lt;input type=&quot;text&quot; name=&quot;person&quot;&gt;&lt;br&gt; File: &lt;input type=&quot;file&quot; name=&quot;secret&quot;&gt;&lt;br&gt; &lt;input type=&quot;submit&quot; value=&quot;Submit&quot;&gt;&lt;/form&gt;HTTP请求头如下:POST /submit.cgi HTTP/1.1Host: example.comUser-Agent: curl/7.46.0Accept: */*Content-Length: 313Expect: 100-continueContent-Type: multipart/form-data; boundary=------------------------d74496d66958873e--------------------------d74496d66958873eContent-Disposition: form-data; name=&quot;person&quot;anonymous--------------------------d74496d66958873eContent-Disposition: form-data; name=&quot;secret&quot;; filename=&quot;file.txt&quot;Content-Type: text/plaincontents of the file--------------------------d74496d66958873e--使用案例：curl -F &#x27;name=Dan&#x27;-F secret=@file.txt -H &#x27;Content-Type: multipart/magic&#x27; https://example.com 当form表单以application&#x2F;x-www-form-urlencoded(默认)提交时，使用-d将’name&#x3D;value’键值对进行URL encode，保证安全。当使用-d传输原数据或json格式时，记得修改Content-Type。 PUT 请求如何发1curl -d &quot;data to PUT&quot; -X PUT http://example.com/new/resource/file http2 http3如何发请求12curl --http2 http://example.com/curl --http3 https://example.com/ curl HTTP cheat sheet Verbose Hide progress extra info Write output Timeout -v -s -w “format” -O -m –trace-ascii -o POST multipart PUT HEAD custom -d “string” -F name&#x3D;value -T -I -X “METHOD” -d @file -F name&#x3D;@file Basic auth read cookies write cookies send cookies user-agent -u user:password -b -c -b “c&#x3D;1; d&#x3D;2” -A “string” Use proxy Headers, add&#x2F;remove follow redirs gzip insecure -x host:port -H “name: value” -L –compressed -k -H “name:” 参考文档: curl 文档主页 curl 帮助指南 HTTP Authentication HTTP HEADERS usingcurl-writeout HTTP Scripting","categories":[{"name":"Linux","slug":"Linux","permalink":"http://wangjstu.github.io/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://wangjstu.github.io/tags/Linux/"}]}],"categories":[{"name":"Shell","slug":"Shell","permalink":"http://wangjstu.github.io/categories/Shell/"},{"name":"Protocols","slug":"Protocols","permalink":"http://wangjstu.github.io/categories/Protocols/"},{"name":"Linux","slug":"Linux","permalink":"http://wangjstu.github.io/categories/Linux/"},{"name":"Git","slug":"Git","permalink":"http://wangjstu.github.io/categories/Git/"},{"name":"Hexo","slug":"Hexo","permalink":"http://wangjstu.github.io/categories/Hexo/"}],"tags":[{"name":"回车","slug":"回车","permalink":"http://wangjstu.github.io/tags/%E5%9B%9E%E8%BD%A6/"},{"name":"换行符","slug":"换行符","permalink":"http://wangjstu.github.io/tags/%E6%8D%A2%E8%A1%8C%E7%AC%A6/"},{"name":"Protocols","slug":"Protocols","permalink":"http://wangjstu.github.io/tags/Protocols/"},{"name":"POP3","slug":"POP3","permalink":"http://wangjstu.github.io/tags/POP3/"},{"name":"SMTP","slug":"SMTP","permalink":"http://wangjstu.github.io/tags/SMTP/"},{"name":"IMAP","slug":"IMAP","permalink":"http://wangjstu.github.io/tags/IMAP/"},{"name":"Linux","slug":"Linux","permalink":"http://wangjstu.github.io/tags/Linux/"},{"name":"tar","slug":"tar","permalink":"http://wangjstu.github.io/tags/tar/"},{"name":"Git","slug":"Git","permalink":"http://wangjstu.github.io/tags/Git/"},{"name":"stash","slug":"stash","permalink":"http://wangjstu.github.io/tags/stash/"},{"name":"Hexo","slug":"Hexo","permalink":"http://wangjstu.github.io/tags/Hexo/"}]}